{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "033b1eb5-8e73-46fa-97e8-30208fb91eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "import sys\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from embedding_layers import SkeletalInputEmbedding\n",
    "from encoder_layers import TransformerEncoder\n",
    "from decoder_layers import TransformerDecoder\n",
    "import TF_helper_functions as hf\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bb28bfa-65b6-4023-a035-35036b5aa2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath='/home/maleen/research_data/Transformers/datasets/training/'\n",
    "# Base path and file information\n",
    "base_name='24_07_25_training_norm'\n",
    "\n",
    "weights_path='/home/maleen/research_data/Transformers/models/TF_tokenised/24_07_31_v1_best_model.pth'\n",
    "\n",
    "filename=datapath+base_name+'.pkl'\n",
    "\n",
    "def load_results_from_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def process_all_datasets(results, input_length=60, predict_length=60):\n",
    "    all_X_pos, all_X_vel, all_X_acc = [], [], []\n",
    "    all_Y_pos, all_Y_vel, all_Y_acc = [], [], []\n",
    "    discarded_frames = {}\n",
    "\n",
    "    for i in range(1, 7):  # Assuming you have 6 datasets\n",
    "        dataset_key = f'dataset{i}'\n",
    "        norm_pos = results[f'{dataset_key}_normpos']\n",
    "        norm_vel = results[f'{dataset_key}_normvel']\n",
    "        norm_acc = results[f'{dataset_key}_normacc']\n",
    "\n",
    "        # Generate sequences for this dataset\n",
    "        X_pos, X_vel, X_acc, Y_pos, Y_vel, Y_acc = hf.generate_sequences(norm_pos, norm_vel, norm_acc, input_length, predict_length)\n",
    "        \n",
    "        all_X_pos.append(X_pos)\n",
    "        all_X_vel.append(X_vel)\n",
    "        all_X_acc.append(X_acc)\n",
    "        all_Y_pos.append(Y_pos)\n",
    "        all_Y_vel.append(Y_vel)\n",
    "        all_Y_acc.append(Y_acc)\n",
    "\n",
    "        # Calculate discarded frames\n",
    "        total_frames = norm_pos.shape[0]\n",
    "        used_frames = X_pos.shape[0] + input_length + predict_length - 1\n",
    "        discarded = total_frames - used_frames\n",
    "        discarded_frames[dataset_key] = discarded\n",
    "\n",
    "    # Combine sequences from all datasets\n",
    "    combined_X_pos = np.concatenate(all_X_pos)\n",
    "    combined_X_vel = np.concatenate(all_X_vel)\n",
    "    combined_X_acc = np.concatenate(all_X_acc)\n",
    "    combined_Y_pos = np.concatenate(all_Y_pos)\n",
    "    combined_Y_vel = np.concatenate(all_Y_vel)\n",
    "    combined_Y_acc = np.concatenate(all_Y_acc)\n",
    "\n",
    "    return (combined_X_pos, combined_X_vel, combined_X_acc, \n",
    "            combined_Y_pos, combined_Y_vel, combined_Y_acc, \n",
    "            discarded_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15b76f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined sequences shapes:\n",
      "X_pos shape: (7667, 30, 6, 3)\n",
      "X_vel shape: (7667, 30, 6, 3)\n",
      "X_acc shape: (7667, 30, 6, 3)\n",
      "Y_pos shape: (7667, 2, 6, 3)\n",
      "Y_vel shape: (7667, 2, 6, 3)\n",
      "Y_acc shape: (7667, 2, 6, 3)\n",
      "\n",
      "Discarded frames per dataset:\n",
      "dataset1: 0 frames\n",
      "dataset2: 0 frames\n",
      "dataset3: 0 frames\n",
      "dataset4: 0 frames\n",
      "dataset5: 0 frames\n",
      "dataset6: 0 frames\n"
     ]
    }
   ],
   "source": [
    "input_length = 30\n",
    "predict_length = 2\n",
    "datasetnum=6\n",
    "\n",
    "# Load the results\n",
    "results = load_results_from_pickle(filename)\n",
    "\n",
    "# Process all datasets and get combined sequences\n",
    "(combined_X_pos, combined_X_vel, combined_X_acc, \n",
    " combined_Y_pos, combined_Y_vel, combined_Y_acc, \n",
    " discarded_frames) = process_all_datasets(results, input_length, predict_length)\n",
    "\n",
    "print(\"Combined sequences shapes:\")\n",
    "print(f\"X_pos shape: {combined_X_pos.shape}\")\n",
    "print(f\"X_vel shape: {combined_X_vel.shape}\")\n",
    "print(f\"X_acc shape: {combined_X_acc.shape}\")\n",
    "print(f\"Y_pos shape: {combined_Y_pos.shape}\")\n",
    "print(f\"Y_vel shape: {combined_Y_vel.shape}\")\n",
    "print(f\"Y_acc shape: {combined_Y_acc.shape}\")\n",
    "\n",
    "print(\"\\nDiscarded frames per dataset:\")\n",
    "for dataset, frames in discarded_frames.items():\n",
    "    print(f\"{dataset}: {frames} frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8abd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already defined your models and set up your training loop\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"CPU\")\n",
    "\n",
    "# Initialize models\n",
    "embed_dim = 128\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "num_joints = 8\n",
    "dropout_rate = 0.1\n",
    "dof=3\n",
    "input_dim = num_joints * dof\n",
    "batch_size = 1\n",
    "\n",
    "\n",
    "start_token = torch.zeros(1, num_joints, 3).to(device)  # Assuming start token\n",
    "\n",
    "# Assuming sequence length\n",
    "# input_length = 30\n",
    "# predict_length = 2\n",
    "\n",
    "\n",
    "# tgt_mask= create_shifted_mask((input_length-1), num_joints)\n",
    "# tgt_mask = tgt_mask.to(device)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_pos_tensor = torch.tensor(combined_X_pos, dtype=torch.float32)\n",
    "X_vel_tensor = torch.tensor(combined_X_vel, dtype=torch.float32)\n",
    "X_acc_tensor = torch.tensor(combined_X_acc, dtype=torch.float32)\n",
    "\n",
    "Y_pos_tensor = torch.tensor(combined_Y_pos, dtype=torch.float32)\n",
    "Y_vel_tensor = torch.tensor(combined_Y_vel, dtype=torch.float32)\n",
    "Y_acc_tensor = torch.tensor(combined_Y_acc, dtype=torch.float32)\n",
    "\n",
    "# Create the full dataset\n",
    "full_dataset = TensorDataset(X_pos_tensor, X_vel_tensor, X_acc_tensor, Y_pos_tensor, Y_vel_tensor, Y_acc_tensor)\n",
    "\n",
    "# Data loader\n",
    "\n",
    "train_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#Defining Models\n",
    "embedding = SkeletalInputEmbedding(input_dim).to(device)\n",
    "encoder = TransformerEncoder(embed_dim, num_heads, num_layers, dropout_rate).to(device)\n",
    "decoder = TransformerDecoder(embed_dim, num_heads, num_layers, num_joints, dropout_rate).to(device)\n",
    "\n",
    "# Loss function\n",
    "#criterion = nn.MSELoss()\n",
    "criterion = hf.MaskedMSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.00001) #0.00001\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "best_loss = float('inf')\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        # Unpack batch\n",
    "        X_pos_batch, X_vel_batch, X_acc_batch, Y_pos_batch, Y_vel_batch, Y_acc_batch = batch\n",
    "\n",
    "        # Memory Data\n",
    "        X_pos_batch = X_pos_batch.to(device)\n",
    "        X_vel_batch = X_vel_batch.to(device)\n",
    "        X_acc_batch = X_acc_batch.to(device)\n",
    "\n",
    "        inputembeddings = embedding(X_pos_batch, X_vel_batch)\n",
    "       \n",
    "        memory = encoder(inputembeddings, src_key_padding_mask=None)\n",
    "\n",
    "        # Output Data\n",
    "        Y_pos_batch = Y_pos_batch.to(device)\n",
    "        Y_vel_batch = Y_vel_batch.to(device)\n",
    "        Y_acc_batch = Y_acc_batch.to(device)\n",
    "\n",
    "        #Target Data\n",
    "        Y_pos_target=X_pos_batch[:, -1:, :, :]\n",
    "        Y_vel_target=Y_vel_batch[:,:-1,:,:]\n",
    "        Y_acc_target=Y_acc_batch[:,:-1,:,:]\n",
    "\n",
    "        #Expected Data \n",
    "        \n",
    "        Y_pos_expected=Y_pos_batch[:,1:,:,:]\n",
    "\n",
    "        targetembeddings = embedding(Y_pos_target, Y_vel_target)\n",
    "\n",
    "        # Perform forward pass through decoder\n",
    "        output = decoder(targetembeddings, memory, tgt_key_padding_mask=None, memory_key_padding_mask=None)\n",
    "\n",
    "        output = output.where(~torch.isnan(output), torch.zeros_like(output))\n",
    "        Y_pos_expected = Y_pos_expected.where(~torch.isnan(Y_pos_expected), torch.zeros_like(Y_pos_expected))\n",
    "\n",
    "                \n",
    "        # print(\"input embeddings: \", np.shape(inputembeddings))\n",
    "        # print(\"memory: \", np.shape(memory))\n",
    "        #print(\"target: \", np.shape(targetembeddings))\n",
    "        #print(\"output: \", np.shape(output))\n",
    "        # print(\"Expected output: \", np.shape(Y_pos_expected))\n",
    "        # Compute loss\n",
    "        loss = criterion(output, Y_pos_expected)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate total loss for the epoch\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    \n",
    "    # Print or log average loss for the epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    # Save model weights if the current epoch has the best loss\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'embedding_state_dict': embedding.state_dict(),\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': avg_loss\n",
    "        }, weights_path)\n",
    "        print(f'Saved new best model with validation loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "# Plot training loss\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4a82bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
